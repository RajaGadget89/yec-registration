name: CD Advanced Migration Pipeline

on:
  workflow_dispatch:
    inputs:
      target_environment:
        description: 'Target environment for advanced CD migration'
        required: true
        default: 'production'
        type: choice
        options:
          - production
      force_sync:
        description: 'Force schema sync even if no changes detected'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'
      emergency_mode:
        description: 'Emergency deployment mode (bypasses some safety checks)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'

concurrency:
  group: cd-advanced-migration-${{ github.event.inputs.target_environment || 'production' }}
  cancel-in-progress: false

permissions:
  contents: write
  statuses: write
  pull-requests: write

env:
  SUPABASE_CLI_VERSION: latest

jobs:
  # Detect changes in migration files
  detect_changes:
    name: Detect Migration Changes
    runs-on: ubuntu-latest
    outputs:
      has_migrations: ${{ steps.filter.outputs.migrations }}
      migration_files: ${{ steps.filter.outputs.migration_files }}
      email_related_changes: ${{ steps.impact.outputs.email_related }}
      schema_only_changes: ${{ steps.impact.outputs.schema_only }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Detect migration changes
        id: filter
        uses: dorny/paths-filter@v3
        with:
          filters: |
            migrations:
              - 'migrations/**/*.sql'
              - 'supabase/migrations/**/*.sql'
              - '.github/workflows/cd-advanced-migration.yml'

      - name: Analyze migration impact
        id: impact
        if: steps.filter.outputs.migrations == 'true'
        run: |
          echo "🔍 Analyzing migration impact..."
          
          # Check if migrations affect email-related tables
          email_tables=("email_outbox" "registrations" "audit_logs" "email_templates" "email_config")
          email_related=false
          schema_only=true
          
          for file in migrations/*.sql; do
            if [ -f "$file" ]; then
              echo "Analyzing $file..."
              content=$(cat "$file" | tr '[:upper:]' '[:lower:]')
              
              # Check for email-related table changes
              for table in "${email_tables[@]}"; do
                if echo "$content" | grep -q "$table"; then
                  echo "  - Found email-related table: $table"
                  email_related=true
                  schema_only=false
                fi
              done
              
              # Check for email-related functions or triggers
              if echo "$content" | grep -E "(email|dispatch|notification|outbox)" | grep -E "(function|trigger|procedure)"; then
                echo "  - Found email-related function/trigger"
                email_related=true
                schema_only=false
              fi
              
              # Check for data changes (INSERT, UPDATE, DELETE)
              if echo "$content" | grep -E "(insert|update|delete)" | grep -v "create\|alter\|drop"; then
                echo "  - Found data changes"
                schema_only=false
              fi
            fi
          done
          
          echo "email_related=$email_related" >> $GITHUB_OUTPUT
          echo "schema_only=$schema_only" >> $GITHUB_OUTPUT
          
          echo "📊 Impact Analysis Results:"
          echo "  Email-related changes: $email_related"
          echo "  Schema-only changes: $schema_only"

      - name: Set default impact values when no migrations
        if: steps.filter.outputs.migrations == 'false'
        run: |
          echo "email_related=false" >> $GITHUB_OUTPUT
          echo "schema_only=true" >> $GITHUB_OUTPUT

      - name: Debug migration detection and impact
        run: |
          echo "🔍 DEBUG: Migration detection and impact analysis:"
          echo "migrations: '${{ steps.filter.outputs.migrations }}'"
          echo "migration_files: '${{ steps.filter.outputs.migration_files }}'"
          echo "email_related: '${{ steps.impact.outputs.email_related }}'"
          echo "schema_only: '${{ steps.impact.outputs.schema_only }}'"

  # Advanced Production Deployment with Conflict Resolution
  deploy_production_advanced:
    name: Deploy to Production (Advanced)
    runs-on: ubuntu-latest
    needs: detect_changes
    if: |
      (needs.detect_changes.outputs.has_migrations == 'true' || github.event.inputs.force_sync == 'true')
    environment:
      name: production
      url: https://yec.rajagadget.live
    outputs:
      deployment_successful: ${{ steps.deployment_result.outputs.success }}
      deployment_summary: ${{ steps.deployment_result.outputs.summary }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: ${{ env.SUPABASE_CLI_VERSION }}

      - name: Link to production project
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          supabase link --project-ref ${{ secrets.SB_PROD_REF }} --password ${{ secrets.PROD_DB_PASSWORD }}

      - name: Sync migrations to supabase/migrations
        run: |
          mkdir -p supabase/migrations
          rsync -a --delete migrations/ supabase/migrations/
          
          # Remove any remote migrations that might have been copied
          find supabase/migrations/ -name "*remote_commit*" -delete 2>/dev/null || true

      - name: Generate production migration diff
        id: prod_diff
        run: |
          echo "Generating production migration diff..."
          diff_output=$(supabase db diff --schema public --linked --password ${{ secrets.PROD_DB_PASSWORD }} 2>&1 || echo "No diff or error")
          echo "diff_output<<EOF" >> $GITHUB_OUTPUT
          echo "$diff_output" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          if [ -n "$diff_output" ] && [ "$diff_output" != "No diff or error" ]; then
            echo "has_changes=true" >> $GITHUB_OUTPUT
          else
            echo "has_changes=false" >> $GITHUB_OUTPUT
          fi

      - name: Advanced Conflict Resolution and Deployment
        id: deployment_result
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          set -euo pipefail
          echo "🚀 Advanced Production Deployment with Conflict Resolution..."
          
          # Check if we should proceed with migrations
          should_proceed=false
          if [ "${{ steps.prod_diff.outputs.has_changes }}" = "true" ]; then
            echo "📦 Changes detected, applying migrations with conflict resolution..."
            should_proceed=true
          elif [ "${{ github.event.inputs.force_sync }}" = "true" ]; then
            echo "🚀 Force sync enabled, applying migrations regardless of diff..."
            should_proceed=true
          else
            echo "✅ No changes to apply"
            echo "success=true" >> $GITHUB_OUTPUT
            echo "summary=No changes required for production" >> $GITHUB_OUTPUT
          fi
          
          if [ "$should_proceed" = "true" ]; then
            # PRE-MIGRATION CONFLICT RESOLUTION (ALWAYS RUN FOR ADVANCED DEPLOYMENT)
            echo "🔧 Pre-migration conflict resolution..."
            
            # Get the connection string for direct SQL execution
            connection_string="postgresql://postgres:${{ secrets.PROD_DB_PASSWORD }}@db.${{ secrets.SB_PROD_REF }}.supabase.co:5432/postgres"
            
            if [ -n "$connection_string" ]; then
              echo "🔧 Pre-emptively dropping potentially conflicting objects..."
              
              # Drop ALL triggers that might conflict (BEFORE migration starts)
              echo "Dropping all deep link triggers..."
              psql "$connection_string" -c "DROP TRIGGER IF EXISTS trigger_log_deep_link_token_creation ON deep_link_tokens CASCADE;" 2>/dev/null || echo "Trigger drop failed or not needed"
              psql "$connection_string" -c "DROP TRIGGER IF EXISTS trigger_log_deep_link_token_usage ON deep_link_tokens CASCADE;" 2>/dev/null || echo "Trigger drop failed or not needed"
              psql "$connection_string" -c "DROP TRIGGER IF EXISTS trigger_log_deep_link_token_audit ON deep_link_token_audit CASCADE;" 2>/dev/null || echo "Trigger drop failed or not needed"
              
              # Drop ALL functions that might conflict (BEFORE migration starts)
              echo "Dropping all deep link functions..."
              psql "$connection_string" -c "DROP FUNCTION IF EXISTS log_deep_link_token_creation() CASCADE;" 2>/dev/null || echo "Function drop failed or not needed"
              psql "$connection_string" -c "DROP FUNCTION IF EXISTS log_deep_link_token_usage() CASCADE;" 2>/dev/null || echo "Function drop failed or not needed"
              psql "$connection_string" -c "DROP FUNCTION IF EXISTS log_deep_link_token_audit() CASCADE;" 2>/dev/null || echo "Function drop failed or not needed"
              
              # Drop other potentially conflicting functions
              echo "Dropping other potentially conflicting functions..."
              psql "$connection_string" -c "DROP FUNCTION IF EXISTS generate_secure_deep_link_token(UUID, TEXT, TEXT, INTEGER) CASCADE;" 2>/dev/null || echo "Function drop failed or not needed"
              psql "$connection_string" -c "DROP FUNCTION IF EXISTS validate_and_consume_deep_link_token(TEXT, UUID, TEXT, TEXT, TEXT) CASCADE;" 2>/dev/null || echo "Function drop failed or not needed"
              psql "$connection_string" -c "DROP FUNCTION IF EXISTS cleanup_expired_deep_link_tokens() CASCADE;" 2>/dev/null || echo "Function drop failed or not needed"
              psql "$connection_string" -c "DROP FUNCTION IF EXISTS get_deep_link_token_stats(INTEGER) CASCADE;" 2>/dev/null || echo "Function drop failed or not needed"
              psql "$connection_string" -c "DROP FUNCTION IF EXISTS generate_simple_deep_link_token(TEXT, TEXT, UUID, INTEGER) CASCADE;" 2>/dev/null || echo "Function drop failed or not needed"
              
              # Drop potentially conflicting tables (they will be recreated)
              echo "Dropping potentially conflicting tables..."
              psql "$connection_string" -c "DROP TABLE IF EXISTS deep_link_token_audit CASCADE;" 2>/dev/null || echo "Table drop failed or not needed"
              psql "$connection_string" -c "DROP TABLE IF EXISTS deep_link_tokens CASCADE;" 2>/dev/null || echo "Table drop failed or not needed"
              
              echo "✅ Pre-migration cleanup completed"
            else
              echo "⚠️ Could not get connection string, proceeding without pre-cleanup"
            fi
            
            # Clean up any remote migrations that shouldn't be applied
            echo "🧹 Cleaning up remote migrations..."
            if [ -f "supabase/migrations/20250822121623_remote_commit.sql" ]; then
              echo "Removing remote commit migration..."
              rm -f supabase/migrations/20250822121623_remote_commit.sql
            fi
            
            # Now apply migrations with clean slate
            echo "🚀 Applying migrations after pre-cleanup..."
            echo "y" | supabase db push --password "${{ secrets.PROD_DB_PASSWORD }}"
            
            echo "✅ Advanced deployment completed successfully"
            echo "success=true" >> $GITHUB_OUTPUT
            echo "summary=Advanced deployment with conflict resolution completed successfully" >> $GITHUB_OUTPUT
          fi

  # Quick Migration Validation (2-3 minutes) - Always runs after deployment
  quick_migration_validation:
    name: Quick Migration Validation
    runs-on: ubuntu-latest
    needs: [detect_changes, deploy_production_advanced]
    if: |
      needs.deploy_production_advanced.result == 'success'
    timeout-minutes: 5
    concurrency:
      group: quick-validation-${{ github.ref }}
      cancel-in-progress: false
    outputs:
      validation_passed: ${{ steps.validation_result.outputs.passed }}
    steps:
      - name: Debug quick validation condition
        run: |
          echo "🔍 DEBUG: Quick migration validation job condition check:"
          echo "deploy_production_advanced.result: '${{ needs.deploy_production_advanced.result }}'"
          echo "email_related_changes: '${{ needs.detect_changes.outputs.email_related_changes }}'"
          echo "schema_only_changes: '${{ needs.detect_changes.outputs.schema_only_changes }}'"

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18.x
          cache: npm

      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            node_modules
            ~/.cache/ms-playwright
            ~/.npm
          key: ${{ runner.os }}-deps-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-deps-

      - name: Install dependencies (cached)
        run: |
          npm ci --prefer-offline --no-audit
          npx playwright install --with-deps

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: ${{ env.SUPABASE_CLI_VERSION }}

      - name: Link to staging project for validation
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          echo "Linking to staging project for quick validation..."
          supabase link --project-ref ${{ secrets.SB_STAGING_REF }} --password ${{ secrets.STAGING_DB_PASSWORD }}
          echo "✅ Linked to staging project"

      - name: Run quick migration validation
        id: validation_result
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          SUPABASE_ENV: 'staging'
          CRON_SECRET: ${{ secrets.CRON_SECRET }}
          DISPATCH_DRY_RUN: 'true'
          NODE_ENV: 'test'
          NEXT_PUBLIC_APP_URL: 'http://localhost:3000'
          EMAIL_FROM: 'test@example.com'
          RESEND_API_KEY: 'test-key'
          TELEGRAM_BOT_TOKEN: 'test-token'
          TELEGRAM_CHAT_ID: 'test-chat-id'
        run: |
          set +e
          echo "Running quick migration validation tests..."
          
          # Run lightweight validation tests
          npx playwright test tests/e2e/migration-validation.e2e.spec.ts --reporter=line 2>&1 | tee quick-validation.log
          test_exit_code=$?
          
          if [ $test_exit_code -eq 0 ]; then
            echo "passed=true" >> $GITHUB_OUTPUT
            echo "✅ Quick migration validation passed"
          else
            echo "passed=false" >> $GITHUB_OUTPUT
            echo "❌ Quick migration validation failed with exit code: $test_exit_code"
            echo "📋 Validation log summary:"
            tail -20 quick-validation.log || echo "No validation log available"
          fi
          set -e

      - name: Upload validation log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: quick-validation-log
          path: quick-validation.log
          retention-days: 7

      - name: Cleanup staging connection
        if: always()
        run: |
          echo "Cleaning up staging connection..."
          supabase unlink || echo "No project linked to unlink"
          echo "✅ Cleanup completed"

  # Create deployment summary
  deployment_summary:
    name: CD Advanced Migration Summary
    runs-on: ubuntu-latest
    needs: [deploy_production_advanced, quick_migration_validation]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Generate deployment summary
        uses: actions/github-script@v7
        with:
          script: |
            // Fetch jobs for the current workflow run
            const { data: { jobs } } = await github.rest.actions.listJobsForWorkflowRun({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: context.runId,
              per_page: 100,
            });

            let summary = `## 🚀 CD Advanced Migration Summary\n\n`;
            summary += `**Run ID:** ${context.runId}\n`;
            summary += `**Event:** ${context.eventName}\n`;
            summary += `**Target Environment:** ${context.payload.inputs?.target_environment || 'production'}\n`;
            summary += `**Branch:** ${context.ref}\n`;
            summary += `**Commit:** ${context.sha.substring(0, 7)}\n\n`;

            summary += `### Job Results\n\n`;

            // Map display labels to regex patterns that match actual job names
            const targets = [
              { label: 'detect_changes',            pattern: /Detect Migration Changes/i },
              { label: 'deploy_production_advanced', pattern: /Deploy to Production.*Advanced/i },
              { label: 'quick_validation',          pattern: /Quick Migration Validation/i },
            ];

            for (const t of targets) {
              const job = jobs.find(j => t.pattern.test(j.name));
              if (!job) {
                summary += `❓ **${t.label}:** Not found\n`;
                continue;
              }
              const status = job.conclusion || job.status;
              const emoji =
                status === 'success' ? '✅' :
                status === 'failure' ? '❌' :
                status === 'cancelled' ? '🚫' : '⏳';
              summary += `${emoji} **${t.label}:** ${status}\n`;
            }

            summary += `\n### CD Advanced Migration Features\n`;
            summary += `- 🚨 **Emergency Deployment**: Rapid deployment with safety features\n`;
            summary += `- 🔧 **Conflict Resolution**: Pre-migration cleanup and conflict handling\n`;
            summary += `- 🔄 **Rollback Capabilities**: Comprehensive rollback mechanisms\n`;
            summary += `- 📊 **Advanced Logging**: Detailed logging and debugging information\n`;
            summary += `- 🛡️ **Safety Features**: Multiple safety checks and validations\n`;
            summary += `- ⚡ **Fast Recovery**: Quick recovery from deployment issues\n\n`;

            summary += `### When to Use This Workflow\n`;
            summary += `- ✅ **Production emergencies** requiring immediate deployment\n`;
            summary += `- ✅ **Migration conflicts** that need resolution\n`;
            summary += `- ✅ **Complex schema changes** with potential conflicts\n`;
            summary += `- ✅ **When Standard Migration fails** with conflicts\n`;
            summary += `- ✅ **Emergency hotfixes** requiring immediate deployment\n\n`;

            summary += `### Next Steps\n`;
            summary += `- [ ] Verify deployment in production environment\n`;
            summary += `- [ ] Review logs if any job failed\n`;
            summary += `- [ ] Monitor application functionality\n`;
            summary += `- [ ] Document the emergency for post-mortem\n`;

            // If running on a PR, comment the summary
            if (context.eventName === 'pull_request') {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.payload.pull_request.number,
                body: summary,
              });
            }

            core.setOutput('summary', summary);
