name: CD Enhanced Migration Pipeline

on:
  workflow_dispatch:
    inputs:
      deployment_mode:
        description: 'Deployment Strategy'
        required: true
        default: 'safe'
        type: choice
        options:
          - safe
          - emergency
      target_environment:
        description: 'Target Environment'
        required: true
        default: 'production'
        type: choice
        options:
          - production

concurrency:
  group: cd-enhanced-migration-${{ github.event.inputs.target_environment || 'production' }}
  cancel-in-progress: true

permissions:
  contents: write
  statuses: write
  pull-requests: write

env:
  SUPABASE_CLI_VERSION: latest

jobs:
  # PHASE 1: Pre-Deployment Safety (2-3 minutes)
  pre_deployment_safety:
    name: Pre-Deployment Safety Check
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      safety_passed: ${{ steps.safety_result.outputs.passed }}
      deployment_ready: ${{ steps.safety_result.outputs.ready }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: ${{ env.SUPABASE_CLI_VERSION }}

      - name: Link to staging for validation
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          echo "🔍 Linking to staging for pre-deployment validation..."
          supabase link --project-ref ${{ secrets.SB_STAGING_REF }} --password ${{ secrets.STAGING_DB_PASSWORD }}

      - name: Comprehensive safety check
        id: safety_result
        run: |
          echo "🔒 Running comprehensive pre-deployment safety checks..."
          
          # Use Supabase CLI to get database connection instead of direct psql
          echo "🔍 Getting database connection from Supabase CLI..."
          db_url=$(supabase db remote commit --password ${{ secrets.STAGING_DB_PASSWORD }} 2>&1 | grep 'postgresql://' | head -1 || echo "")
          
          if [ -z "$db_url" ]; then
            echo "❌ Failed to get database connection from Supabase CLI"
            echo "passed=false" >> $GITHUB_OUTPUT
            echo "ready=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "Using database connection: $db_url"
          
          # 1. Verify required schema exists
          echo "📋 Checking required schema..."
          has_attempts=$(psql "$db_url" -t -c "SELECT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name = 'email_outbox' AND column_name = 'attempts')" 2>/dev/null | tr -d ' ')
          has_max_attempts=$(psql "$db_url" -t -c "SELECT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name = 'email_outbox' AND column_name = 'max_attempts')" 2>/dev/null | tr -d ' ')
          
          # Additional debugging: Check if table exists and show all columns
          table_exists=$(psql "$db_url" -t -c "SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = 'email_outbox')" 2>/dev/null | tr -d ' ')
          echo "email_outbox table exists: $table_exists"
          
          if [ "$table_exists" = "t" ]; then
            echo "All columns in email_outbox table:"
            psql "$db_url" -t -c "SELECT column_name FROM information_schema.columns WHERE table_name = 'email_outbox' ORDER BY ordinal_position" 2>/dev/null || echo "Failed to list columns"
          fi
          
          if [ "$has_attempts" != "t" ] || [ "$has_max_attempts" != "t" ]; then
            echo "⚠️ Supabase CLI connection method failed, trying fallback method..."
            
            # Fallback: Try direct connection with Supabase project context
            fallback_connection="postgresql://postgres:${{ secrets.STAGING_DB_PASSWORD }}@db.${{ secrets.SB_STAGING_REF }}.supabase.co:5432/postgres"
            
            echo "Trying fallback connection: $fallback_connection"
            
            has_attempts_fallback=$(psql "$fallback_connection" -t -c "SELECT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name = 'email_outbox' AND column_name = 'attempts')" 2>/dev/null | tr -d ' ')
            has_max_attempts_fallback=$(psql "$fallback_connection" -t -c "SELECT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name = 'email_outbox' AND column_name = 'max_attempts')" 2>/dev/null | tr -d ' ')
            
            if [ "$has_attempts_fallback" = "t" ] && [ "$has_max_attempts_fallback" = "t" ]; then
              echo "✅ Staging database has required schema (fallback method)"
              has_attempts="t"
              has_max_attempts="t"
            else
              echo "❌ Staging database missing required schema (both methods failed)"
              echo "passed=false" >> $GITHUB_OUTPUT
              echo "ready=false" >> $GITHUB_OUTPUT
              exit 1
            fi
          fi
          
          # 2. Check database connectivity
          echo "🌐 Testing database connectivity..."
          if ! psql "$db_url" -c "SELECT 1;" >/dev/null 2>&1; then
            echo "❌ Database connectivity test failed"
            echo "passed=false" >> $GITHUB_OUTPUT
            echo "ready=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # 3. Check for pending migrations
          echo "📦 Checking for pending migrations..."
          pending_migrations=$(supabase db diff --schema public --linked --password ${{ secrets.STAGING_DB_PASSWORD }} 2>/dev/null | wc -l)
          if [ "$pending_migrations" -gt 0 ]; then
            echo "⚠️ Found pending migrations in staging"
            echo "passed=true" >> $GITHUB_OUTPUT
            echo "ready=true" >> $GITHUB_OUTPUT
          else
            echo "✅ No pending migrations"
            echo "passed=true" >> $GITHUB_OUTPUT
            echo "ready=false" >> $GITHUB_OUTPUT
          fi
          
          echo "✅ Pre-deployment safety checks passed"

      - name: Cleanup staging connection
        if: always()
        run: |
          echo "🧹 Cleaning up staging connection..."
          supabase unlink || echo "No project linked to unlink"

  # PHASE 2: Migration Detection (1-2 minutes)
  detect_migrations:
    name: Detect Migration Changes
    runs-on: ubuntu-latest
    needs: pre_deployment_safety
    if: needs.pre_deployment_safety.outputs.safety_passed == 'true'
    timeout-minutes: 3
    outputs:
      has_migrations: ${{ steps.migration_detection.outputs.has_migrations }}
      migration_files: ${{ steps.migration_detection.outputs.migration_files }}
      email_related_changes: ${{ steps.migration_detection.outputs.email_related }}
      schema_only_changes: ${{ steps.migration_detection.outputs.schema_only }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: ${{ env.SUPABASE_CLI_VERSION }}

      - name: Link to production for migration detection
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          echo "🔍 Linking to production for migration detection..."
          supabase link --project-ref ${{ secrets.SB_PROD_REF }} --password ${{ secrets.PROD_DB_PASSWORD }}

      - name: Detect migration changes
        id: migration_detection
        run: |
          echo "🔍 Detecting migration changes..."
          
          # Check if there are any migration files
          if [ ! -d "migrations" ] || [ -z "$(ls -A migrations/*.sql 2>/dev/null)" ]; then
            echo "📭 No migration files found"
            echo "has_migrations=false" >> $GITHUB_OUTPUT
            echo "migration_files=" >> $GITHUB_OUTPUT
            echo "email_related=false" >> $GITHUB_OUTPUT
            echo "schema_only=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Get list of migration files
          migration_files=$(find migrations -name "*.sql" -type f | sort | tr '\n' ',' | sed 's/,$//')
          echo "📦 Found migration files: $migration_files"
          
          # Check if there are differences between local and remote
          echo "🔍 Checking for differences between local and remote..."
          diff_output=$(supabase db diff --schema public --linked --password ${{ secrets.PROD_DB_PASSWORD }} 2>&1 || echo "No diff or error")
          
          if [ -n "$diff_output" ] && [ "$diff_output" != "No diff or error" ]; then
            echo "✅ Migration changes detected"
            echo "has_migrations=true" >> $GITHUB_OUTPUT
            echo "migration_files=$migration_files" >> $GITHUB_OUTPUT
            
            # Analyze migration impact
            echo "🔍 Analyzing migration impact..."
            email_related=false
            schema_only=true
            
            # Check if migrations affect email-related tables
            email_tables=("email_outbox" "registrations" "audit_logs" "email_templates" "email_config")
            
            for file in migrations/*.sql; do
              if [ -f "$file" ]; then
                echo "Analyzing $file..."
                content=$(cat "$file" | tr '[:upper:]' '[:lower:]')
                
                for table in "${email_tables[@]}"; do
                  if echo "$content" | grep -q "$table"; then
                    echo "  - Affects email-related table: $table"
                    email_related=true
                    schema_only=false
                  fi
                done
              fi
            done
            
            echo "📊 Migration Impact Analysis:"
            echo "  Email-related changes: $email_related"
            echo "  Schema-only changes: $schema_only"
            
            echo "email_related=$email_related" >> $GITHUB_OUTPUT
            echo "schema_only=$schema_only" >> $GITHUB_OUTPUT
          else
            echo "✅ No migration changes detected"
            echo "has_migrations=false" >> $GITHUB_OUTPUT
            echo "migration_files=$migration_files" >> $GITHUB_OUTPUT
            echo "email_related=false" >> $GITHUB_OUTPUT
            echo "schema_only=true" >> $GITHUB_OUTPUT
          fi

      - name: Cleanup production connection
        if: always()
        run: |
          echo "🧹 Cleaning up production connection..."
          supabase unlink || echo "No project linked to unlink"

  # PHASE 3: Production Health Check (1-2 minutes)
  production_health_check:
    name: Production Health Check
    runs-on: ubuntu-latest
    needs: [pre_deployment_safety, detect_migrations]
    if: |
      needs.pre_deployment_safety.outputs.safety_passed == 'true' &&
      needs.detect_migrations.outputs.has_migrations == 'true'
    timeout-minutes: 3
    outputs:
      production_healthy: ${{ steps.health_result.outputs.healthy }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: ${{ env.SUPABASE_CLI_VERSION }}

      - name: Link to production
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          echo "🏥 Linking to production for health check..."
          supabase link --project-ref ${{ secrets.SB_PROD_REF }} --password ${{ secrets.PROD_DB_PASSWORD }}

      - name: Production health assessment
        id: health_result
        run: |
          echo "🏥 Assessing production database health..."
          
          # Use direct connection approach (drift-safe, idempotent)
          # This avoids the unreliable supabase db remote commit command
          echo "Using direct database connection for health assessment..."
          
          # Direct connection with Supabase project context (proven reliable method)
          db_url="postgresql://postgres:${{ secrets.PROD_DB_PASSWORD }}@db.${{ secrets.SB_PROD_REF }}.supabase.co:5432/postgres"
          
          echo "Using production database connection: $db_url"
          
          # Test connectivity first
          echo "Testing database connectivity..."
          if ! psql "$db_url" -c "SELECT 1;" >/dev/null 2>&1; then
            echo "❌ Production database connectivity failed"
            echo "healthy=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "✅ Database connectivity confirmed"
          
          # 1. Basic connectivity test
          if ! psql "$db_url" -c "SELECT 1;" >/dev/null 2>&1; then
            echo "❌ Production database connectivity failed"
            echo "healthy=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # 2. Check database version and status
          db_version=$(psql "$db_url" -t -c "SELECT version();" 2>/dev/null | head -1)
          echo "📊 Database version: $db_version"
          
          # 3. Check for active connections (basic load check)
          active_connections=$(psql "$db_url" -t -c "SELECT count(*) FROM pg_stat_activity WHERE state = 'active';" 2>/dev/null | tr -d ' ')
          echo "🔗 Active connections: $active_connections"
          
          # 4. Check for locks (basic contention check)
          locks_count=$(psql "$db_url" -t -c "SELECT count(*) FROM pg_locks WHERE NOT granted;" 2>/dev/null | tr -d ' ')
          echo "🔒 Pending locks: $locks_count"
          
          if [ "$locks_count" -gt 10 ]; then
            echo "⚠️ High lock contention detected"
            echo "healthy=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "✅ Production database is healthy"
          echo "healthy=true" >> $GITHUB_OUTPUT

      - name: Cleanup production connection
        if: always()
        run: |
          echo "🧹 Cleaning up production connection..."
          supabase unlink || echo "No project linked to unlink"

  # PHASE 4: Migration Execution (3-5 minutes)
  execute_migration:
    name: Execute Migration
    runs-on: ubuntu-latest
    needs: [pre_deployment_safety, detect_migrations, production_health_check]
    if: |
      needs.pre_deployment_safety.outputs.safety_passed == 'true' &&
      needs.detect_migrations.outputs.has_migrations == 'true' &&
      needs.production_health_check.outputs.production_healthy == 'true'
    environment:
      name: production
      url: https://yec.rajagadget.live
    outputs:
      migration_success: ${{ steps.migration_result.outputs.success }}
      rollback_needed: ${{ steps.migration_result.outputs.rollback }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: ${{ env.SUPABASE_CLI_VERSION }}

      - name: Link to production
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          echo "🚀 Linking to production for migration execution..."
          supabase link --project-ref ${{ secrets.SB_PROD_REF }} --password ${{ secrets.PROD_DB_PASSWORD }}

      - name: Sync migrations
        run: |
          echo "📦 Syncing migration files..."
          mkdir -p supabase/migrations
          rsync -a --delete migrations/ supabase/migrations/

      - name: Execute migration with rollback protection
        id: migration_result
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          set -euo pipefail
          echo "🚀 Executing migration with enhanced safety..."
          
          # Create backup point (log current state)
          echo "📸 Creating deployment checkpoint..."
          # Note: We skip the unreliable supabase db remote commit command
          # and proceed directly with migration execution
          echo "Current migrations: Will be checked during migration execution"
          
          # Generate migration diff
          echo "🔍 Analyzing migration requirements..."
          diff_output=$(supabase db diff --schema public --linked --password ${{ secrets.PROD_DB_PASSWORD }} 2>&1 || echo "No diff or error")
          
          if [ -n "$diff_output" ] && [ "$diff_output" != "No diff or error" ]; then
            echo "📦 Changes detected, proceeding with migration..."
            
            # Prod preflight — detect existing PKs & unguarded statements
            echo "🔍 Prod preflight — detect existing PKs & unguarded statements"
            
            echo "Pulling production schema (read‑only)..."
            # Export current prod schema to a temp file without changing migration history
            supabase db pull --password "${{ secrets.PROD_DB_PASSWORD }}" --debug || {
              echo '::error::supabase db pull failed; ensure link + credentials are correct.'
              exit 1
            }
            SCHEMA_FILE="supabase/schema.sql"
            test -s "$SCHEMA_FILE" || { echo '::error::schema.sql not found after db pull'; exit 1; }

            echo "Checking PKs on prod schema..."
            if grep -qE "CONSTRAINT\s+access_log_pkey\s+PRIMARY KEY" "$SCHEMA_FILE"; then
              echo "✔ access_log_pkey exists on prod"
            else
              echo "⚠ access_log_pkey NOT found in prod schema dump"
            fi
            if grep -qE "CONSTRAINT\s+event_log_pkey\s+PRIMARY KEY" "$SCHEMA_FILE"; then
              echo "✔ event_log_pkey exists on prod"
            else
              echo "ℹ event_log_pkey not found (ok if your install doesn't use it)"
            fi

            echo "Scanning migrations for unguarded PK additions..."
            if grep -R --line-number -E "ADD CONSTRAINT .*PRIMARY KEY USING INDEX" migrations/ | grep -vi "DO \$\$" ; then
              echo "::error::Unguarded 'ADD CONSTRAINT ... USING INDEX' statements detected in migrations/. Wrap them in DO $$ IF NOT EXISTS $$ blocks."
              exit 1
            fi

            echo "Preflight OK — ready to push"
            
            # Determine migration strategy based on deployment mode
            if [ "${{ github.event.inputs.deployment_mode }}" = "emergency" ]; then
              echo "🚨 Emergency mode: Using --include-all flag"
              supabase db push --include-all --password ${{ secrets.PROD_DB_PASSWORD }} || {
                echo "::error::db push failed — check for unguarded 'ADD CONSTRAINT ... USING INDEX' in migrations."
                exit 1
              }
            else
              echo "🛡️ Safe mode: Checking migration order..."
              dry_run_output=$(supabase db push --dry-run --password ${{ secrets.PROD_DB_PASSWORD }} 2>&1 || true)
              
              if echo "$dry_run_output" | grep -q "Found local migration files to be inserted before the last migration"; then
                echo "⚠️ Migration order issue detected. Using --include-all flag..."
                supabase db push --include-all --password ${{ secrets.PROD_DB_PASSWORD }} || {
                  echo "::error::db push failed — check for unguarded 'ADD CONSTRAINT ... USING INDEX' in migrations."
                  exit 1
                }
              else
                echo "✅ Standard migration push..."
                supabase db push --password ${{ secrets.PROD_DB_PASSWORD }} || {
                  echo "::error::db push failed — check for unguarded 'ADD CONSTRAINT ... USING INDEX' in migrations."
                  exit 1
                }
              fi
            fi
            
            echo "✅ Migration executed successfully"
            echo "success=true" >> $GITHUB_OUTPUT
            echo "rollback=false" >> $GITHUB_OUTPUT
          else
            echo "✅ No changes to deploy"
            echo "success=true" >> $GITHUB_OUTPUT
            echo "rollback=false" >> $GITHUB_OUTPUT
          fi

      - name: Cleanup production connection
        if: always()
        run: |
          echo "🧹 Cleaning up production connection..."
          supabase unlink || echo "No project linked to unlink"

  # PHASE 5: Post-Deployment Verification (2-3 minutes)
  post_deployment_verification:
    name: Post-Deployment Verification
    runs-on: ubuntu-latest
    needs: execute_migration
    if: needs.execute_migration.outputs.migration_success == 'true'
    timeout-minutes: 5
    outputs:
      verification_passed: ${{ steps.verification_result.outputs.passed }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: ${{ env.SUPABASE_CLI_VERSION }}

      - name: Link to production for verification
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          echo "🔍 Linking to production for post-deployment verification..."
          supabase link --project-ref ${{ secrets.SB_PROD_REF }} --password ${{ secrets.PROD_DB_PASSWORD }}

      - name: Comprehensive verification
        id: verification_result
        run: |
          echo "🔍 Running comprehensive post-deployment verification..."
          
          # Use direct connection approach (drift-safe, idempotent)
          # This avoids the unreliable supabase db remote commit command
          echo "Using direct database connection for verification..."
          
          # Direct connection with Supabase project context (proven reliable method)
          db_url="postgresql://postgres:${{ secrets.PROD_DB_PASSWORD }}@db.${{ secrets.SB_PROD_REF }}.supabase.co:5432/postgres"
          
          echo "Using production database connection: $db_url"
          
          # Test connectivity first
          echo "Testing database connectivity..."
          if ! psql "$db_url" -c "SELECT 1;" >/dev/null 2>&1; then
            echo "❌ Production database connectivity failed"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "✅ Database connectivity confirmed"
          
          # 1. Verify schema changes were applied
          echo "📋 Verifying schema changes..."
          has_attempts=$(psql "$db_url" -t -c "SELECT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name = 'email_outbox' AND column_name = 'attempts')" 2>/dev/null | tr -d ' ')
          has_max_attempts=$(psql "$db_url" -t -c "SELECT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name = 'email_outbox' AND column_name = 'max_attempts')" 2>/dev/null | tr -d ' ')
          
          # Additional debugging: Check if table exists and show all columns
          table_exists=$(psql "$db_url" -t -c "SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = 'email_outbox')" 2>/dev/null | tr -d ' ')
          echo "email_outbox table exists: $table_exists"
          
          if [ "$table_exists" = "t" ]; then
            echo "All columns in email_outbox table:"
            psql "$db_url" -t -c "SELECT column_name FROM information_schema.columns WHERE table_name = 'email_outbox' ORDER BY ordinal_position" 2>/dev/null || echo "Failed to list columns"
          fi
          
          if [ "$has_attempts" != "t" ] || [ "$has_max_attempts" != "t" ]; then
            echo "❌ Production database missing required schema"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # 2. Verify database integrity
          echo "🔒 Checking database integrity..."
          integrity_check=$(psql "$db_url" -t -c "SELECT count(*) FROM pg_constraint WHERE convalidated = false;" 2>/dev/null | tr -d ' ')
          if [ "$integrity_check" -gt 0 ]; then
            echo "❌ Database integrity issues detected"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # 3. Verify application connectivity
          echo "🌐 Testing application connectivity..."
          if ! psql "$db_url" -c "SELECT 1;" >/dev/null 2>&1; then
            echo "❌ Application connectivity test failed"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "✅ Post-deployment verification passed"
          echo "passed=true" >> $GITHUB_OUTPUT

      - name: Cleanup production connection
        if: always()
        run: |
          echo "🧹 Cleaning up production connection..."
          supabase unlink || echo "No project linked to unlink"

  # PHASE 6: Emergency Rollback (if needed)
  emergency_rollback:
    name: Emergency Rollback
    runs-on: ubuntu-latest
    needs: [execute_migration, post_deployment_verification]
    if: |
      (needs.execute_migration.outputs.rollback_needed == 'true' || 
       needs.post_deployment_verification.outputs.verification_passed == 'false') &&
      needs.execute_migration.result == 'success'
    environment:
      name: production
      url: https://yec.rajagadget.live
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: ${{ env.SUPABASE_CLI_VERSION }}

      - name: Link to production for rollback
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          echo "🔄 Linking to production for emergency rollback..."
          supabase link --project-ref ${{ secrets.SB_PROD_REF }} --password ${{ secrets.PROD_DB_PASSWORD }}

      - name: Execute emergency rollback
        run: |
          echo "🚨 Executing emergency rollback..."
          
          # This is a placeholder for rollback logic
          # In a real implementation, you would:
          # 1. Restore from backup
          # 2. Apply rollback migrations
          # 3. Verify rollback success
          
          echo "⚠️ Emergency rollback triggered - manual intervention required"
          echo "Please contact the database administrator for immediate assistance"
          
          # Exit with error to indicate rollback was needed
          exit 1

      - name: Cleanup production connection
        if: always()
        run: |
          echo "🧹 Cleaning up production connection..."
          supabase unlink || echo "No project linked to unlink"

  # PHASE 7: Deployment Summary (always runs)
  deployment_summary:
    name: Enhanced Deployment Summary
    runs-on: ubuntu-latest
    needs: [pre_deployment_safety, detect_migrations, production_health_check, execute_migration, post_deployment_verification, emergency_rollback]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Generate comprehensive summary
        uses: actions/github-script@v7
        with:
          script: |
            // Fetch jobs for the current workflow run
            const { data: { jobs } } = await github.rest.actions.listJobsForWorkflowRun({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: context.runId,
              per_page: 100,
            });

            let summary = `## 🚀 Enhanced Migration Deployment Summary\n\n`;
            summary += `**Run ID:** ${context.runId}\n`;
            summary += `**Deployment Mode:** ${context.payload.inputs?.deployment_mode || 'safe'}\n`;
            summary += `**Target Environment:** ${context.payload.inputs?.target_environment || 'production'}\n`;
            summary += `**Branch:** ${context.ref}\n`;
            summary += `**Commit:** ${context.sha.substring(0, 7)}\n\n`;

            summary += `### Phase Results\n\n`;

            // Map display labels to regex patterns that match actual job names
            const targets = [
              { label: 'pre_deployment_safety',      pattern: /Pre-Deployment Safety Check/i },
              { label: 'detect_migrations',          pattern: /Detect Migration Changes/i },
              { label: 'production_health_check',    pattern: /Production Health Check/i },
              { label: 'execute_migration',          pattern: /Execute Migration/i },
              { label: 'post_deployment_verification', pattern: /Post-Deployment Verification/i },
              { label: 'emergency_rollback',         pattern: /Emergency Rollback/i },
            ];

            for (const t of targets) {
              const job = jobs.find(j => t.pattern.test(j.name));
              if (!job) {
                summary += `❓ **${t.label}:** Not found\n`;
                continue;
              }
              const status = job.conclusion || job.status;
              const emoji =
                status === 'success' ? '✅' :
                status === 'failure' ? '❌' :
                status === 'cancelled' ? '🚫' : '⏳';
              summary += `${emoji} **${t.label}:** ${status}\n`;
            }

            summary += `\n### Enhanced Migration Features\n`;
            summary += `- 🛡️ **Multi-Phase Safety:** Pre-deployment, migration detection, health check, execution, verification\n`;
            summary += `- 🚨 **Emergency Mode:** Bypass safety checks for urgent deployments\n`;
            summary += `- 🔄 **Rollback Protection:** Automatic rollback triggers on failure\n`;
            summary += `- 📊 **Comprehensive Monitoring:** Health checks, integrity verification\n`;
            summary += `- ⚡ **Time Optimized:** Skip expensive operations when no migrations detected\n`;
            summary += `- 🎯 **Sequential Strategy:** Proper job dependencies ensure correct execution order\n\n`;

            summary += `### Deployment Modes\n`;
            summary += `- **Safe Mode:** Full safety checks, migration order validation\n`;
            summary += `- **Emergency Mode:** Bypass safety checks, force migration with --include-all\n\n`;

            summary += `### Next Steps\n`;
            summary += `- [ ] Verify application functionality\n`;
            summary += `- [ ] Monitor error rates and performance\n`;
            summary += `- [ ] Test email dispatch functionality\n`;
            summary += `- [ ] Document any issues for future improvements\n`;

            // If running on a PR, comment the summary
            if (context.eventName === 'pull_request') {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.payload.pull_request.number,
                body: summary,
              });
            }

            core.setOutput('summary', summary);
