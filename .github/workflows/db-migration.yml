name: Database Migration Pipeline

on:
  push:
    branches: [ develop, staging, bugfix/recover-core-services-system ]
    paths:
      - 'migrations/**'
      - 'supabase/migrations/**'
      - '.github/workflows/db-migration.yml'
  pull_request:
    branches: [ main, develop, staging, bugfix/recover-core-services-system ]
    paths:
      - 'migrations/**'
      - 'supabase/migrations/**'
      - '.github/workflows/db-migration.yml'
  workflow_dispatch:
    inputs:
      target_environment:
        description: 'Target environment for migration'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production
      skip_tests:
        description: 'Skip migration tests (not recommended)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'
      force_migration:
        description: 'Force migration even if no changes detected'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'

concurrency:
  group: db-migration-${{ github.ref }}-${{ github.event.inputs.target_environment || 'staging' }}
  cancel-in-progress: false

permissions:
  contents: write
  statuses: write
  pull-requests: write

env:
  SUPABASE_CLI_VERSION: latest

jobs:
  # Detect changes in migration files
  detect_changes:
    name: Detect Migration Changes
    runs-on: ubuntu-latest
    outputs:
      has_migrations: ${{ steps.filter.outputs.migrations }}
      migration_files: ${{ steps.filter.outputs.migration_files }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Detect migration changes
        id: filter
        uses: dorny/paths-filter@v3
        with:
          filters: |
            migrations:
              - 'migrations/**/*.sql'
              - 'supabase/migrations/**/*.sql'
              - '.github/workflows/db-migration.yml'

      - name: List migration files
        if: steps.filter.outputs.migrations == 'true'
        run: |
          echo "Migration files detected:"
          find migrations/ -name "*.sql" -type f | sort
          echo "Supabase migration files:"
          find supabase/migrations/ -name "*.sql" -type f | sort

      # Always report status to satisfy ruleset requirements
      - name: Report required context (ruleset-compat)
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        env:
          JOB_STATUS: ${{ job.status }}
        with:
          script: |
            const stateMap = { success: 'success', failure: 'failure', cancelled: 'failure' };
            const state = stateMap[process.env.JOB_STATUS] || 'failure';
            const sha = context.payload.pull_request.head.sha;
            await github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha,
              state,
              context: 'Database Migration Pipeline / Detect Migration Changes (pull_request)',
              description: `Reported from run ${context.runId}`,
              target_url: `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`
            })

  # Validate migration files
  validate_migrations:
    name: Validate Migration Files
    runs-on: ubuntu-latest
    needs: detect_changes
    if: needs.detect_changes.outputs.has_migrations == 'true' || github.event.inputs.force_migration == 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: ${{ env.SUPABASE_CLI_VERSION }}

      - name: Validate migration syntax
        run: |
          echo "Validating migration files..."
          
          # Check for SQL syntax errors in migration files
          for file in migrations/*.sql; do
            if [ -f "$file" ]; then
              echo "Validating $file..."
              # Basic SQL syntax check (you can enhance this with more sophisticated validation)
              if ! grep -q ";" "$file"; then
                echo "❌ Error: $file appears to be missing semicolons"
                exit 1
              fi
              echo "✅ $file syntax looks valid"
            fi
          done

      - name: Check migration naming convention
        run: |
          echo "Checking migration naming convention..."
          
          # Ensure migrations follow timestamp naming convention
          for file in migrations/*.sql; do
            if [ -f "$file" ]; then
              filename=$(basename "$file")
              if ! [[ $filename =~ ^[0-9]{14}_.*\.sql$ ]]; then
                echo "❌ Error: $filename doesn't follow timestamp naming convention (YYYYMMDDHHMMSS_description.sql)"
                exit 1
              fi
              echo "✅ $filename follows naming convention"
            fi
          done

      - name: Validate migration order
        run: |
          echo "Validating migration order..."
          
          # Check that migrations are in chronological order
          prev_timestamp=""
          for file in $(ls migrations/*.sql 2>/dev/null | sort); do
            if [ -f "$file" ]; then
              filename=$(basename "$file")
              timestamp=$(echo "$filename" | cut -d'_' -f1)
              
              if [ -n "$prev_timestamp" ] && [ "$timestamp" -lt "$prev_timestamp" ]; then
                echo "❌ Error: Migration $filename has timestamp $timestamp which is before previous migration $prev_timestamp"
                exit 1
              fi
              
              prev_timestamp="$timestamp"
              echo "✅ $filename timestamp: $timestamp"
            fi
          done

      # Always report status to satisfy ruleset requirements
      - name: Report required context (ruleset-compat)
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        env:
          JOB_STATUS: ${{ job.status }}
        with:
          script: |
            const stateMap = { success: 'success', failure: 'failure', cancelled: 'failure' };
            const state = stateMap[process.env.JOB_STATUS] || 'failure';
            const sha = context.payload.pull_request.head.sha;
            await github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha,
              state,
              context: 'Database Migration Pipeline / Validate Migration Files (pull_request)',
              description: `Reported from run ${context.runId}`,
              target_url: `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`
            })

  # Test migrations on shadow database
  test_migrations:
    name: Test Migrations (Shadow DB)
    runs-on: ubuntu-latest
    needs: [detect_changes, validate_migrations]
    if: (needs.detect_changes.outputs.has_migrations == 'true' || github.event.inputs.force_migration == 'true') && github.event.inputs.skip_tests != 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: ${{ env.SUPABASE_CLI_VERSION }}

      - name: Start local Supabase (shadow)
        run: |
          supabase start
          supabase status

      - name: Sync migrations to supabase/migrations
        run: |
          mkdir -p supabase/migrations
          rsync -a --delete migrations/ supabase/migrations/

      - name: Apply migrations to shadow database
        env:
          SHADOW_DB_URL: postgresql://postgres:postgres@localhost:54322/postgres
        run: |
          echo "Applying migrations to shadow database..."
          set -euo pipefail
          
          # Reset shadow database and apply all migrations
          printf 'y\n' | supabase db reset --db-url "$SHADOW_DB_URL"
          
          echo "✅ Migrations applied successfully to shadow database"

      - name: Run database tests
        env:
          SHADOW_DB_URL: postgresql://postgres:postgres@localhost:54322/postgres
        run: |
          echo "Running database tests..."
          
          # Basic connectivity test
          psql "$SHADOW_DB_URL" -c "SELECT version();" || exit 1
          
          # Test that all expected tables exist
          psql "$SHADOW_DB_URL" -c "
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'public' 
            AND table_type = 'BASE TABLE'
            ORDER BY table_name;
          " || exit 1
          
          echo "✅ Database tests passed"

      - name: Stop local Supabase
        if: always()
        run: supabase stop

      # Always report status to satisfy ruleset requirements
      - name: Report required context (ruleset-compat)
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        env:
          JOB_STATUS: ${{ job.status }}
        with:
          script: |
            const stateMap = { success: 'success', failure: 'failure', cancelled: 'failure' };
            const state = stateMap[process.env.JOB_STATUS] || 'failure';
            const sha = context.payload.pull_request.head.sha;
            await github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha,
              state,
              context: 'Database Migration Pipeline / Test Migrations (Shadow DB) (pull_request)',
              description: `Reported from run ${context.runId}`,
              target_url: `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`
            })

  # Deploy to staging environment
  deploy_staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [detect_changes, validate_migrations, test_migrations]
    if: |
      (needs.detect_changes.outputs.has_migrations == 'true' || github.event.inputs.force_migration == 'true') &&
             (github.event.inputs.target_environment == 'staging' || github.event.inputs.target_environment == null) &&
      (github.ref == 'refs/heads/staging' || github.ref == 'refs/heads/develop' || github.event_name == 'workflow_dispatch' || github.event_name == 'pull_request')
    # Staging deployment - uses repository secrets for staging environment
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: ${{ env.SUPABASE_CLI_VERSION }}

      - name: Link to staging project
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          supabase link --project-ref ${{ secrets.SB_STAGING_REF }} --password ${{ secrets.STAGING_DB_PASSWORD }}

      - name: Sync migrations to supabase/migrations
        run: |
          mkdir -p supabase/migrations
          rsync -a --delete migrations/ supabase/migrations/

      - name: Generate migration diff
        id: diff
        run: |
          echo "Generating migration diff..."
          diff_output=$(supabase db diff --schema public --linked --password ${{ secrets.STAGING_DB_PASSWORD }} 2>&1 || echo "No diff or error")
          echo "diff_output<<EOF" >> $GITHUB_OUTPUT
          echo "$diff_output" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          if [ -n "$diff_output" ] && [ "$diff_output" != "No diff or error" ]; then
            echo "has_changes=true" >> $GITHUB_OUTPUT
          else
            echo "has_changes=false" >> $GITHUB_OUTPUT
          fi

      - name: Push migrations to staging
        if: steps.diff.outputs.has_changes == 'true'
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          echo "Pushing migrations to staging..."
          supabase db push --dry-run --password ${{ secrets.STAGING_DB_PASSWORD }}
          supabase db push --password ${{ secrets.STAGING_DB_PASSWORD }}
          echo "✅ Migrations deployed to staging"

      - name: No changes to deploy
        if: steps.diff.outputs.has_changes == 'false'
        run: |
          echo "No database changes detected. Skipping deployment."

      - name: Verify staging deployment
        if: steps.diff.outputs.has_changes == 'true'
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          echo "Verifying staging deployment..."
          
          # Link again to ensure we're connected
          supabase link --project-ref ${{ secrets.SB_STAGING_REF }} --password ${{ secrets.STAGING_DB_PASSWORD }}
          
          # Check that migrations were applied
          supabase db diff --schema public --linked --password ${{ secrets.STAGING_DB_PASSWORD }} || echo "No pending changes (good!)"

  # Deploy to production (manual approval required)
  deploy_production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [deploy_staging]
    if: |
      github.event.inputs.target_environment == 'production' &&
      (github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch')
    environment:
      name: production
      url: https://yec.rajagadget.live
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: ${{ env.SUPABASE_CLI_VERSION }}

      - name: Link to production project
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          supabase link --project-ref ${{ secrets.SB_PROD_REF }} --password ${{ secrets.PROD_DB_PASSWORD }}

      - name: Sync migrations to supabase/migrations
        run: |
          mkdir -p supabase/migrations
          rsync -a --delete migrations/ supabase/migrations/

      - name: Generate production migration diff
        id: prod_diff
        run: |
          echo "Generating production migration diff..."
          diff_output=$(supabase db diff --schema public --linked --password ${{ secrets.PROD_DB_PASSWORD }} 2>&1 || echo "No diff or error")
          echo "diff_output<<EOF" >> $GITHUB_OUTPUT
          echo "$diff_output" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          if [ -n "$diff_output" ] && [ "$diff_output" != "No diff or error" ]; then
            echo "has_changes=true" >> $GITHUB_OUTPUT
          else
            echo "has_changes=false" >> $GITHUB_OUTPUT
          fi

      - name: Push migrations to production
        if: steps.prod_diff.outputs.has_changes == 'true'
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          echo "Pushing migrations to production..."
          supabase db push --dry-run --password ${{ secrets.PROD_DB_PASSWORD }}
          supabase db push --password ${{ secrets.PROD_DB_PASSWORD }}
          echo "✅ Migrations deployed to production"

      - name: No production changes to deploy
        if: steps.prod_diff.outputs.has_changes == 'false'
        run: |
          echo "No database changes detected for production. Skipping deployment."

      - name: Verify production deployment
        if: steps.prod_diff.outputs.has_changes == 'true'
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          echo "Verifying production deployment..."
          
          # Link again to ensure we're connected
          supabase link --project-ref ${{ secrets.SB_PROD_REF }} --password ${{ secrets.PROD_DB_PASSWORD }}
          
          # Check that migrations were applied
          supabase db diff --schema public --linked --password ${{ secrets.PROD_DB_PASSWORD }} || echo "No pending changes (good!)"

  # Run E2E tests after database migrations are complete
  e2e_tests_after_migration:
    name: E2E Tests (After Migration)
    runs-on: ubuntu-latest
    needs: [deploy_staging, deploy_production]
    if: |
      always() && 
      (needs.deploy_staging.result == 'success' || needs.deploy_staging.result == 'skipped') &&
      (needs.deploy_production.result == 'success' || needs.deploy_production.result == 'skipped')
    outputs:
      tests_passed: ${{ steps.test_result.outputs.passed }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18
          cache: npm

      - name: Install OS dependencies for node-canvas
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential libcairo2-dev libpango1.0-dev libjpeg-dev \
            libgif-dev librsvg2-dev libpixman-1-dev

      - name: Install dependencies
        run: |
          npm ci
          npx playwright install --with-deps

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: ${{ env.SUPABASE_CLI_VERSION }}

      - name: Start local Supabase
        run: |
          supabase start
          supabase status

      - name: Run E2E Tests
        id: test_result
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          SUPABASE_ENV: 'staging'
          CRON_SECRET: ${{ secrets.CRON_SECRET }}
          DISPATCH_DRY_RUN: 'true'
          NODE_ENV: 'test'
          NEXT_PUBLIC_APP_URL: 'http://localhost:3000'
          EMAIL_FROM: 'test@example.com'
          RESEND_API_KEY: 'test-key'
          TELEGRAM_BOT_TOKEN: 'test-token'
          TELEGRAM_CHAT_ID: 'test-chat-id'
        run: |
          set +e
          npm run e2e:local 2>&1 | tee e2e-ci.log
          if [ $? -eq 0 ]; then
            echo "passed=true" >> $GITHUB_OUTPUT
          else
            echo "passed=false" >> $GITHUB_OUTPUT
          fi
          set -e

      - name: Upload E2E Log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-ci-log
          path: e2e-ci.log
          retention-days: 7

      - name: Attempt Auto-Fix
        if: |
          failure() && 
          needs.e2e_tests_after_migration.outputs.tests_passed == 'false' &&
          github.event_name == 'pull_request'
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          SUPABASE_ENV: 'staging'
          CRON_SECRET: ${{ secrets.CRON_SECRET }}
          DISPATCH_DRY_RUN: 'true'
          NODE_ENV: 'test'
          NEXT_PUBLIC_APP_URL: 'http://localhost:3000'
          EMAIL_FROM: 'test@example.com'
          RESEND_API_KEY: 'test-key'
          TELEGRAM_BOT_TOKEN: 'test-token'
          TELEGRAM_CHAT_ID: 'test-chat-id'
        run: |
          npm run e2e:auto-fix:ci || true

      - name: Stop local Supabase
        if: always()
        run: supabase stop

      # Always report status to satisfy ruleset requirements
      - name: Report required context (ruleset-compat)
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        env:
          JOB_STATUS: ${{ job.status }}
        with:
          script: |
            const stateMap = { success: 'success', failure: 'failure', cancelled: 'failure' };
            const state = stateMap[process.env.JOB_STATUS] || 'failure';
            const sha = context.payload.pull_request.head.sha;
            await github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha,
              state,
              context: 'Database Migration Pipeline / E2E Tests (After Migration) (pull_request)',
              description: `Reported from run ${context.runId}`,
              target_url: `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`
            })



  # Create deployment summary
  deployment_summary:
    name: Deployment Summary
    runs-on: ubuntu-latest
    needs: [deploy_staging, deploy_production, e2e_tests_after_migration]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Generate deployment summary
        uses: actions/github-script@v7
        with:
          script: |
            // Fetch jobs for the current workflow run (this returns the jobs list)
            const { data: { jobs } } = await github.rest.actions.listJobsForWorkflowRun({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: context.runId,
              per_page: 100,
            });

            let summary = `## Database Migration Summary\n\n`;
            summary += `**Run ID:** ${context.runId}\n`;
            summary += `**Event:** ${context.eventName}\n`;
            summary += `**Branch:** ${context.ref}\n`;
            summary += `**Commit:** ${context.sha.substring(0, 7)}\n\n`;

            summary += `### Job Results\n\n`;

            // Map display labels to regex patterns that match actual job names
            const targets = [
              { label: 'detect_changes',            pattern: /Detect Migration Changes/i },
              { label: 'validate_migrations',       pattern: /Validate Migration Files/i },
              { label: 'test_migrations',           pattern: /Test Migrations.*Shadow DB/i },
              { label: 'deploy_staging',            pattern: /Deploy to Staging/i },
              { label: 'deploy_production',         pattern: /Deploy to Production/i },
              { label: 'e2e_tests_after_migration', pattern: /E2E Tests \(After Migration\)/i },
            ];

            for (const t of targets) {
              const job = jobs.find(j => t.pattern.test(j.name));
              if (!job) {
                summary += `❓ **${t.label}:** Not found\n`;
                continue;
              }
              const status = job.conclusion || job.status; // conclusion may be null while running
              const emoji =
                status === 'success' ? '✅' :
                status === 'failure' ? '❌' :
                status === 'cancelled' ? '🚫' : '⏳';
              summary += `${emoji} **${t.label}:** ${status}\n`;
            }

            summary += `\n### Next Steps\n`;
            summary += `- [ ] Verify staging\n`;
            summary += `- [ ] Review logs if any job failed\n`;
            summary += `- [ ] Promote to production when stable\n`;

            // If running on a PR, comment the summary
            if (context.eventName === 'pull_request') {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.payload.pull_request.number,
                body: summary,
              });
            }

            core.setOutput('summary', summary);
